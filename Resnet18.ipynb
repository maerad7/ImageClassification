{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet18.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet 18"
      ],
      "metadata": {
        "id": "00F8HOup_myp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "luK-gzSQ_mFU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- residual connection"
      ],
      "metadata": {
        "id": "eXA5v-MrBHes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Residual(nn.Module):\n",
        "  def __init__(self, in_channel, out_channel, use_1x1Conv=False, stride=1):\n",
        "    super.__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, padding=1, stride= strides)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "    self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "\n",
        "    if use_1x1Conv:\n",
        "      self.conv3 = nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=strides)\n",
        "    else:\n",
        "      self.conv3 = None\n",
        "  \n",
        "  def forward(self, X):\n",
        "    out = F.relu(self.bn1(self.conv1(X)))\n",
        "    out = self.bn2(self.conv2(out))\n",
        "    if self.conv3:\n",
        "      X = self.conv3(X)\n",
        "    out = out + X\n",
        "    return F.relu(out)"
      ],
      "metadata": {
        "id": "ZBnRUl5S_xx8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residualBlock(in_channel, out_channel, num_residuals, first_block=False):\n",
        "  blks = []\n",
        "  for i in range(num_residuals):\n",
        "    if i == 0 and not first_block:\n",
        "      blks.append(Residual(in_channel, out_channel, use_1x1Conv=True, stride=2))\n",
        "    else:\n",
        "      blks.append(Residual(out_channel, out_channel))\n",
        "\n",
        "  return blks"
      ],
      "metadata": {
        "id": "BVQDADacBDrz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self, input_channel, n_classes):\n",
        "    super().__init__()\n",
        "    self.b1 = nn.Sequential(\n",
        "        nn.Conv2d(input_channel, 64, kernel_size=7, stride=2 , padding=3),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "    )\n",
        "    self.b2 = nn.Sequential(*residualBlock(64,64,2,first_block=True))\n",
        "    self.b3 = nn.Sequential(*residualBlock(64,128,2))\n",
        "    self.b4 = nn.Sequential(*residualBlock(128,256,2))\n",
        "    self.b5 = nn.Sequential(*residualBlock(256,512,2))\n",
        "    slef.finalLayer = nn.Sequential(\n",
        "        nn.AdaptiveAvgPool2d((1,1)),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(512,n_classes)\n",
        "    )\n",
        "\n",
        "    self.b1.apply(self.init_weights)\n",
        "    self.b2.apply(self.init_weights)\n",
        "    self.b3.apply(self.init_weights)\n",
        "    self.b4.apply(self.init_weights)\n",
        "    self.b5.apply(self.init_weights)\n",
        "    self.finalLayer.apply(self.init_weights)\n",
        "\n",
        "  def init_weights(self, layer):\n",
        "      if type(layer) == nn.Conv2d:\n",
        "          nn.init.kaiming_normal_(layer.weight, mode='fan_out')\n",
        "      if type(layer) == nn.Linear:\n",
        "          nn.init.normal_(layer.weight, std=1e-3)\n",
        "      if type(layer) == nn.BatchNorm2d:\n",
        "          nn.init.constant_(layer.weight, 1)\n",
        "          nn.init.constant_(layer.bias, 0)\n",
        "\n",
        "  def forward(self, X):\n",
        "      out = self.b1(X)\n",
        "      out = self.b2(out)\n",
        "      out = self.b3(out)\n",
        "      out = self.b4(out)\n",
        "      out = self.b5(out)\n",
        "      out = self.finalLayer(out)\n",
        "\n",
        "      return out"
      ],
      "metadata": {
        "id": "6h4cHQ7CBkc_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NNUcgCijEq2U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}